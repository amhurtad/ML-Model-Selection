{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>P7</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>P8</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>eyeDetection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4329.23</td>\n",
       "      <td>4009.23</td>\n",
       "      <td>4289.23</td>\n",
       "      <td>4148.21</td>\n",
       "      <td>4350.26</td>\n",
       "      <td>4586.15</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4641.03</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4238.46</td>\n",
       "      <td>4211.28</td>\n",
       "      <td>4280.51</td>\n",
       "      <td>4635.90</td>\n",
       "      <td>4393.85</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4324.62</td>\n",
       "      <td>4004.62</td>\n",
       "      <td>4293.85</td>\n",
       "      <td>4148.72</td>\n",
       "      <td>4342.05</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4638.97</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4226.67</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4279.49</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4384.10</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4327.69</td>\n",
       "      <td>4006.67</td>\n",
       "      <td>4295.38</td>\n",
       "      <td>4156.41</td>\n",
       "      <td>4336.92</td>\n",
       "      <td>4583.59</td>\n",
       "      <td>4096.92</td>\n",
       "      <td>4630.26</td>\n",
       "      <td>4207.69</td>\n",
       "      <td>4222.05</td>\n",
       "      <td>4206.67</td>\n",
       "      <td>4282.05</td>\n",
       "      <td>4628.72</td>\n",
       "      <td>4389.23</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4328.72</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4296.41</td>\n",
       "      <td>4155.90</td>\n",
       "      <td>4343.59</td>\n",
       "      <td>4582.56</td>\n",
       "      <td>4097.44</td>\n",
       "      <td>4630.77</td>\n",
       "      <td>4217.44</td>\n",
       "      <td>4235.38</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4287.69</td>\n",
       "      <td>4632.31</td>\n",
       "      <td>4396.41</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4326.15</td>\n",
       "      <td>4011.79</td>\n",
       "      <td>4292.31</td>\n",
       "      <td>4151.28</td>\n",
       "      <td>4347.69</td>\n",
       "      <td>4586.67</td>\n",
       "      <td>4095.90</td>\n",
       "      <td>4627.69</td>\n",
       "      <td>4210.77</td>\n",
       "      <td>4244.10</td>\n",
       "      <td>4212.82</td>\n",
       "      <td>4288.21</td>\n",
       "      <td>4632.82</td>\n",
       "      <td>4398.46</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AF3       F7       F3      FC5       T7       P7       O1       O2  \\\n",
       "0  4329.23  4009.23  4289.23  4148.21  4350.26  4586.15  4096.92  4641.03   \n",
       "1  4324.62  4004.62  4293.85  4148.72  4342.05  4586.67  4097.44  4638.97   \n",
       "2  4327.69  4006.67  4295.38  4156.41  4336.92  4583.59  4096.92  4630.26   \n",
       "3  4328.72  4011.79  4296.41  4155.90  4343.59  4582.56  4097.44  4630.77   \n",
       "4  4326.15  4011.79  4292.31  4151.28  4347.69  4586.67  4095.90  4627.69   \n",
       "\n",
       "        P8       T8      FC6       F4       F8      AF4 eyeDetection  \n",
       "0  4222.05  4238.46  4211.28  4280.51  4635.90  4393.85         b'0'  \n",
       "1  4210.77  4226.67  4207.69  4279.49  4632.82  4384.10         b'0'  \n",
       "2  4207.69  4222.05  4206.67  4282.05  4628.72  4389.23         b'0'  \n",
       "3  4217.44  4235.38  4210.77  4287.69  4632.31  4396.41         b'0'  \n",
       "4  4210.77  4244.10  4212.82  4288.21  4632.82  4398.46         b'0'  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = arff.loadarff('EEG Eye State.arff')\n",
    "eeg_data = pd.DataFrame(data[0])\n",
    "eeg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8257\n",
       "1    6723\n",
       "Name: eyeDetection, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Have to change 'eyeDetection' values to stricly be 1 and -1\n",
    "eeg_data['eyeDetection'] = np.where((eeg_data['eyeDetection'] == \"b'0'\"), -1, eeg_data['eyeDetection'])\n",
    "eeg_data['eyeDetection'] = np.where((eeg_data['eyeDetection'] == \"b'1'\"), 1, eeg_data['eyeDetection'])\n",
    "\n",
    "#Ensure all values are numeric\n",
    "eeg_data['eyeDetection'] = pd.to_numeric(eeg_data['eyeDetection'])\n",
    "\n",
    "#Value counts\n",
    "eeg_data['eyeDetection'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    8257\n",
       " 1    6723\n",
       "Name: eyeDetection, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change 0 values to -1\n",
    "eeg_data['eyeDetection'] = np.where((eeg_data['eyeDetection'] == 0), -1, eeg_data['eyeDetection'])\n",
    "eeg_data['eyeDetection'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I have to standardize all numerical columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def scale_columns(dataset, cols_scale):\n",
    "    for col in cols_scale:\n",
    "        dataset[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(eeg_data[col])), columns=[col])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AF3</th>\n",
       "      <th>F7</th>\n",
       "      <th>F3</th>\n",
       "      <th>FC5</th>\n",
       "      <th>T7</th>\n",
       "      <th>P7</th>\n",
       "      <th>O1</th>\n",
       "      <th>O2</th>\n",
       "      <th>P8</th>\n",
       "      <th>T8</th>\n",
       "      <th>FC6</th>\n",
       "      <th>F4</th>\n",
       "      <th>F8</th>\n",
       "      <th>AF4</th>\n",
       "      <th>eyeDetection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002934</td>\n",
       "      <td>-0.011704</td>\n",
       "      <td>0.567398</td>\n",
       "      <td>-0.003209</td>\n",
       "      <td>0.245236</td>\n",
       "      <td>-0.019788</td>\n",
       "      <td>-0.002930</td>\n",
       "      <td>0.852568</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.187750</td>\n",
       "      <td>0.233510</td>\n",
       "      <td>0.030745</td>\n",
       "      <td>0.017127</td>\n",
       "      <td>-0.003834</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001084</td>\n",
       "      <td>-0.112052</td>\n",
       "      <td>0.671390</td>\n",
       "      <td>-0.003111</td>\n",
       "      <td>0.008893</td>\n",
       "      <td>-0.019610</td>\n",
       "      <td>-0.002817</td>\n",
       "      <td>0.782241</td>\n",
       "      <td>-0.003771</td>\n",
       "      <td>-0.122109</td>\n",
       "      <td>0.138498</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>0.014578</td>\n",
       "      <td>-0.005489</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002316</td>\n",
       "      <td>-0.067429</td>\n",
       "      <td>0.705829</td>\n",
       "      <td>-0.001636</td>\n",
       "      <td>-0.138785</td>\n",
       "      <td>-0.020663</td>\n",
       "      <td>-0.002930</td>\n",
       "      <td>0.484886</td>\n",
       "      <td>-0.005213</td>\n",
       "      <td>-0.243529</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>0.067815</td>\n",
       "      <td>0.011185</td>\n",
       "      <td>-0.004618</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.044020</td>\n",
       "      <td>0.729013</td>\n",
       "      <td>-0.001734</td>\n",
       "      <td>0.053225</td>\n",
       "      <td>-0.021015</td>\n",
       "      <td>-0.002817</td>\n",
       "      <td>0.502297</td>\n",
       "      <td>-0.000649</td>\n",
       "      <td>0.106803</td>\n",
       "      <td>0.220012</td>\n",
       "      <td>0.203578</td>\n",
       "      <td>0.014156</td>\n",
       "      <td>-0.003399</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.044020</td>\n",
       "      <td>0.636726</td>\n",
       "      <td>-0.002620</td>\n",
       "      <td>0.171253</td>\n",
       "      <td>-0.019610</td>\n",
       "      <td>-0.003152</td>\n",
       "      <td>0.397148</td>\n",
       "      <td>-0.003771</td>\n",
       "      <td>0.335977</td>\n",
       "      <td>0.274267</td>\n",
       "      <td>0.216095</td>\n",
       "      <td>0.014578</td>\n",
       "      <td>-0.003051</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AF3        F7        F3       FC5        T7        P7        O1  \\\n",
       "0  0.002934 -0.011704  0.567398 -0.003209  0.245236 -0.019788 -0.002930   \n",
       "1  0.001084 -0.112052  0.671390 -0.003111  0.008893 -0.019610 -0.002817   \n",
       "2  0.002316 -0.067429  0.705829 -0.001636 -0.138785 -0.020663 -0.002930   \n",
       "3  0.002730  0.044020  0.729013 -0.001734  0.053225 -0.021015 -0.002817   \n",
       "4  0.001698  0.044020  0.636726 -0.002620  0.171253 -0.019610 -0.003152   \n",
       "\n",
       "         O2        P8        T8       FC6        F4        F8       AF4  \\\n",
       "0  0.852568  0.001509  0.187750  0.233510  0.030745  0.017127 -0.003834   \n",
       "1  0.782241 -0.003771 -0.122109  0.138498  0.006192  0.014578 -0.005489   \n",
       "2  0.484886 -0.005213 -0.243529  0.111503  0.067815  0.011185 -0.004618   \n",
       "3  0.502297 -0.000649  0.106803  0.220012  0.203578  0.014156 -0.003399   \n",
       "4  0.397148 -0.003771  0.335977  0.274267  0.216095  0.014578 -0.003051   \n",
       "\n",
       "   eyeDetection  \n",
       "0            -1  \n",
       "1            -1  \n",
       "2            -1  \n",
       "3            -1  \n",
       "4            -1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_eeg_data = scale_columns(eeg_data, [i for i in list(eeg_data.columns) if i not in ['eyeDetection']])\n",
    "scaled_eeg_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting all the samples we will need for each algorithm\n",
    "all_samples = []\n",
    "\n",
    "for sample in range(0,5):\n",
    "    all_samples.append(scaled_eeg_data.sample(n=5000, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14980"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scaled_eeg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    8257\n",
       " 1    6723\n",
       "Name: eyeDetection, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_eeg_data['eyeDetection'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lists to save models and training/testing sets\n",
    "all_models = []\n",
    "X_training_sets = []\n",
    "y_training_sets = []\n",
    "X_testing_sets = []\n",
    "y_testing_sets = []\n",
    "\n",
    "#lists to save best params\n",
    "accuracy_best_params = []\n",
    "roc_auc_best_params = []\n",
    "f1_best_params = []\n",
    "\n",
    "#looping across each sample for each trial\n",
    "for sample in all_samples:\n",
    "    X_train = sample.iloc[:, :-1]\n",
    "    y_train = sample.iloc[:, -1]\n",
    "    X_training_sets.append(X_train)\n",
    "    y_training_sets.append(y_train)\n",
    "    \n",
    "    #Separating rows for the test set that were not in the sample\n",
    "    ix = [i for i in scaled_eeg_data.index if i not in sample.index]\n",
    "    test_set = scaled_eeg_data.loc[ix]\n",
    "    X_test = test_set.iloc[:, :-1]\n",
    "    y_test = test_set.iloc[:, -1]\n",
    "    X_testing_sets.append(X_test)\n",
    "    y_testing_sets.append(y_test)\n",
    "    \n",
    "    #Initiating classifier\n",
    "    log_reg = LogisticRegression(max_iter=10000)\n",
    "    \n",
    "    grid_values = [{'solver':['saga'],\n",
    "                   'penalty': ['l1', 'l2'],\n",
    "                   'C': [.00000001, .0000001, .000001, .00001, .0001, .001, .01, .1, 1, 10, 100, 1000, 10000]},\n",
    "                   {'solver':['lbfgs'],\n",
    "                   'penalty': ['l2'],\n",
    "                   'C': [.00000001, .0000001, .000001, .00001, .0001, .001, .01, .1, 1, 10, 100, 1000, 10000]},\n",
    "                   {'solver':['lbfgs', 'saga'],\n",
    "                   'penalty': ['none'],}\n",
    "                   ]\n",
    "    clf = GridSearchCV(estimator = log_reg, param_grid = grid_values, cv = StratifiedKFold(n_splits=5),\n",
    "                      scoring = ['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False, verbose=0)\n",
    "    \n",
    "    model = clf.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy_best_params.append(model.cv_results_['params'][np.argmin(model.cv_results_['rank_test_accuracy'])])\n",
    "    roc_auc_best_params.append(model.cv_results_['params'][np.argmin(model.cv_results_['rank_test_roc_auc_ovr'])])\n",
    "    f1_best_params.append(model.cv_results_['params'][np.argmin(model.cv_results_['rank_test_f1_micro'])])\n",
    "    \n",
    "    all_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'penalty': 'none', 'solver': 'lbfgs'},\n",
       " {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       " {'penalty': 'none', 'solver': 'lbfgs'},\n",
       " {'C': 10000, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       " {'penalty': 'none', 'solver': 'lbfgs'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'penalty': 'none', 'solver': 'lbfgs'},\n",
       " {'penalty': 'none', 'solver': 'lbfgs'},\n",
       " {'penalty': 'none', 'solver': 'lbfgs'},\n",
       " {'penalty': 'none', 'solver': 'lbfgs'},\n",
       " {'penalty': 'none', 'solver': 'lbfgs'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'penalty': 'none', 'solver': 'lbfgs'},\n",
       " {'C': 1000, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       " {'penalty': 'none', 'solver': 'lbfgs'},\n",
       " {'C': 10000, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       " {'penalty': 'none', 'solver': 'lbfgs'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to loop across all models from each metric, train on entire sample, and then predict on test set\n",
    "accuracy_test_errors = []\n",
    "accuracy_train_errors = []\n",
    "for param in accuracy_best_params:\n",
    "    \n",
    "    n = 0\n",
    "    if 'C' in param:\n",
    "        \n",
    "        logreg_clf = LogisticRegression(penalty = param['penalty'], solver = param['solver'], C = param['C'], max_iter = 10000)\n",
    "        model = logreg_clf.fit(X_training_sets[n], y_training_sets[n])\n",
    "    else:\n",
    "        \n",
    "        logreg_clf = LogisticRegression(penalty = param['penalty'], solver = param['solver'],  max_iter = 10000)\n",
    "        model = logreg_clf.fit(X_training_sets[n], y_training_sets[n])\n",
    "    \n",
    "    y_pred = model.predict(X_testing_sets[n])\n",
    "    accuracy_test_errors.append(accuracy_score(y_testing_sets[n], y_pred))\n",
    "    \n",
    "    y_pred_train = model.predict(X_training_sets[n])\n",
    "    accuracy_train_errors.append(accuracy_score(y_training_sets[n], y_pred_train))\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6366733466933868,\n",
       " 0.6333667334669338,\n",
       " 0.6366733466933868,\n",
       " 0.6371743486973948,\n",
       " 0.6366733466933868]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6432, 0.6358, 0.6432, 0.6402, 0.6432]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_test_errors = []\n",
    "roc_auc_train_errors = []\n",
    "for param in roc_auc_best_params:\n",
    "    \n",
    "    n = 0\n",
    "    \n",
    "    if 'C' in param:\n",
    "        \n",
    "        logreg_clf = LogisticRegression(penalty = param['penalty'], solver = param['solver'], C = param['C'], max_iter = 10000)\n",
    "        model = logreg_clf.fit(X_training_sets[n], y_training_sets[n])\n",
    "    else:\n",
    "        \n",
    "        logreg_clf = LogisticRegression(penalty = param['penalty'], solver = param['solver'],  max_iter = 10000)\n",
    "        model = logreg_clf.fit(X_training_sets[n], y_training_sets[n])\n",
    "    \n",
    "    y_pred2 = model.predict(X_testing_sets[n])\n",
    "    roc_auc_test_errors.append(roc_auc_score(y_testing_sets[n], y_pred2))\n",
    "    \n",
    "    y_pred_train2 = model.predict(X_training_sets[n])\n",
    "    roc_auc_train_errors.append(roc_auc_score(y_training_sets[n], y_pred_train2))\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6231276136836025,\n",
       " 0.6231276136836025,\n",
       " 0.6231276136836025,\n",
       " 0.6231276136836025,\n",
       " 0.6231276136836025]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6324617101413792,\n",
       " 0.6324617101413792,\n",
       " 0.6324617101413792,\n",
       " 0.6324617101413792,\n",
       " 0.6324617101413792]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_train_errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_test_errors = []\n",
    "f1_score_train_errors = []\n",
    "for param in f1_best_params:\n",
    "    \n",
    "    n = 0\n",
    "    \n",
    "    if 'C' in param:\n",
    "        \n",
    "        logreg_clf = LogisticRegression(penalty = param['penalty'], solver = param['solver'], C = param['C'], max_iter = 10000)\n",
    "        model = logreg_clf.fit(X_training_sets[n], y_training_sets[n])\n",
    "    else:\n",
    "        \n",
    "        logreg_clf = LogisticRegression(penalty = param['penalty'], solver = param['solver'],  max_iter = 10000)\n",
    "        model = logreg_clf.fit(X_training_sets[n], y_training_sets[n])\n",
    "    \n",
    "    y_pred3 = model.predict(X_testing_sets[n])\n",
    "    f1_score_test_errors.append(f1_score(y_testing_sets[n], y_pred3))\n",
    "    \n",
    "    y_pred_train3 = model.predict(X_training_sets[n])\n",
    "    f1_score_train_errors.append(f1_score(y_training_sets[n], y_pred_train3))\n",
    "    \n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5502356735301415,\n",
       " 0.5433670285785599,\n",
       " 0.5502356735301415,\n",
       " 0.5505771378925157,\n",
       " 0.5502356735301415]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5665694849368319,\n",
       " 0.5546588407923698,\n",
       " 0.5665694849368319,\n",
       " 0.5623935782048164,\n",
       " 0.5665694849368319]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_train_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lists to save models and training/testing sets\n",
    "all_models_knn = []\n",
    "X_training_sets_knn = []\n",
    "y_training_sets_knn = []\n",
    "X_testing_sets_knn = []\n",
    "y_testing_sets_knn = []\n",
    "\n",
    "#lists to save best params\n",
    "accuracy_best_params_knn = []\n",
    "roc_auc_best_params_knn = []\n",
    "f1_best_params_knn = []\n",
    "\n",
    "#looping across each sample for each trial\n",
    "for sample in all_samples:\n",
    "    X_train_knn = sample.iloc[:, :-1]\n",
    "    y_train_knn = sample.iloc[:, -1]\n",
    "    X_training_sets_knn.append(X_train_knn)\n",
    "    y_training_sets_knn.append(y_train_knn)\n",
    "    \n",
    "    #Separating rows for the test set that were not in the sample\n",
    "    ix_knn = [i for i in scaled_eeg_data.index if i not in sample.index]\n",
    "    test_set_knn = scaled_eeg_data.loc[ix]\n",
    "    X_test_knn = test_set_knn.iloc[:, :-1]\n",
    "    y_test_knn = test_set_knn.iloc[:, -1]\n",
    "    X_testing_sets_knn.append(X_test_knn)\n",
    "    y_testing_sets_knn.append(y_test_knn)\n",
    "    \n",
    "    #Initiating classifier\n",
    "    knn = KNeighborsClassifier()\n",
    "    \n",
    "    grid_values = {'n_neighbors' : list(range(1,105,4))}\n",
    "    \n",
    "    clf_knn = GridSearchCV(estimator = knn, param_grid = grid_values, cv = StratifiedKFold(n_splits=5),\n",
    "                      scoring = ['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False, verbose=0)\n",
    "    \n",
    "    model_knn = clf_knn.fit(X_train_knn, y_train_knn)\n",
    "    \n",
    "    accuracy_best_params_knn.append(model_knn.cv_results_['params'][np.argmin(model_knn.cv_results_['rank_test_accuracy'])])\n",
    "    roc_auc_best_params_knn.append(model_knn.cv_results_['params'][np.argmin(model_knn.cv_results_['rank_test_roc_auc_ovr'])])\n",
    "    f1_best_params_knn.append(model_knn.cv_results_['params'][np.argmin(model_knn.cv_results_['rank_test_f1_micro'])])\n",
    "    \n",
    "    all_models_knn.append(model_knn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_neighbors': 5},\n",
       " {'n_neighbors': 1},\n",
       " {'n_neighbors': 1},\n",
       " {'n_neighbors': 5},\n",
       " {'n_neighbors': 1}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_best_params_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_neighbors': 5},\n",
       " {'n_neighbors': 5},\n",
       " {'n_neighbors': 9},\n",
       " {'n_neighbors': 9},\n",
       " {'n_neighbors': 5}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_best_params_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_neighbors': 5},\n",
       " {'n_neighbors': 1},\n",
       " {'n_neighbors': 1},\n",
       " {'n_neighbors': 5},\n",
       " {'n_neighbors': 1}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_best_params_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to loop across all models from each metric, train on entire sample, and then predict on test set\n",
    "accuracy_test_errors_knn = []\n",
    "accuracy_train_errors_knn = []\n",
    "for param in accuracy_best_params_knn:\n",
    "    \n",
    "    n_knn = 0\n",
    "    \n",
    "    knn_clf = KNeighborsClassifier(n_neighbors = param['n_neighbors'])\n",
    "    model = knn_clf.fit(X_training_sets_knn[n_knn], y_training_sets_knn[n_knn])\n",
    "    \n",
    "    y_pred_knn = model.predict(X_testing_sets_knn[n_knn])\n",
    "    accuracy_test_errors_knn.append(accuracy_score(y_testing_sets_knn[n_knn], y_pred_knn))\n",
    "    \n",
    "    y_pred_train_knn = model.predict(X_training_sets_knn[n_knn])\n",
    "    accuracy_train_errors_knn.append(accuracy_score(y_training_sets_knn[n_knn], y_pred_train_knn))\n",
    "    \n",
    "    n_knn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8207414829659319,\n",
       " 0.8652304609218436,\n",
       " 0.8652304609218436,\n",
       " 0.8207414829659319,\n",
       " 0.8652304609218436]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test_errors_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8766, 1.0, 1.0, 0.8766, 1.0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train_errors_knn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_test_errors_knn = []\n",
    "roc_auc_train_errors_knn = []\n",
    "for param in roc_auc_best_params_knn:\n",
    "    \n",
    "    n_knn = 0\n",
    "    \n",
    "    knn_clf2 = KNeighborsClassifier(n_neighbors = param['n_neighbors'])\n",
    "    model = knn_clf2.fit(X_training_sets_knn[n_knn], y_training_sets_knn[n_knn])\n",
    "    \n",
    "    y_pred_knn2 = model.predict(X_testing_sets_knn[n_knn])\n",
    "    roc_auc_test_errors_knn.append(roc_auc_score(y_testing_sets_knn[n_knn], y_pred_knn2))\n",
    "    \n",
    "    y_pred_train_knn2 = model.predict(X_training_sets_knn[n_knn])\n",
    "    roc_auc_train_errors_knn.append(roc_auc_score(y_training_sets_knn[n_knn], y_pred_train_knn2))\n",
    "    \n",
    "    n_knn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8175869828047664,\n",
       " 0.8175869828047664,\n",
       " 0.8029711174314488,\n",
       " 0.8029711174314488,\n",
       " 0.8175869828047664]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_test_errors_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8744413752237604,\n",
       " 0.8744413752237604,\n",
       " 0.8463682474524097,\n",
       " 0.8463682474524097,\n",
       " 0.8744413752237604]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_train_errors_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_test_errors_knn = []\n",
    "f1_score_train_errors_knn = []\n",
    "for param in f1_best_params_knn:\n",
    "    \n",
    "    n_knn = 0\n",
    "    \n",
    "    knn_clf3 = KNeighborsClassifier(n_neighbors = param['n_neighbors'])\n",
    "    model = knn_clf3.fit(X_training_sets_knn[n_knn], y_training_sets_knn[n_knn])\n",
    "    \n",
    "    y_pred_knn3 = model.predict(X_testing_sets_knn[n_knn])\n",
    "    f1_score_test_errors_knn.append(f1_score(y_testing_sets_knn[n_knn], y_pred_knn3))\n",
    "    \n",
    "    y_pred_train_knn3 = model.predict(X_training_sets_knn[n_knn])\n",
    "    f1_score_train_errors_knn.append(f1_score(y_training_sets_knn[n_knn], y_pred_train_knn3))\n",
    "    \n",
    "    \n",
    "    n_knn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7975557315831164,\n",
       " 0.850339379103149,\n",
       " 0.850339379103149,\n",
       " 0.7975557315831164,\n",
       " 0.850339379103149]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_test_errors_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8625529071062598, 1.0, 1.0, 0.8625529071062598, 1.0]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_train_errors_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lists to save models and training/testing sets\n",
    "all_models_dt = []\n",
    "X_training_sets_dt = []\n",
    "y_training_sets_dt = []\n",
    "X_testing_sets_dt = []\n",
    "y_testing_sets_dt = []\n",
    "\n",
    "#lists to save best params\n",
    "accuracy_best_params_dt = []\n",
    "roc_auc_best_params_dt = []\n",
    "f1_best_params_dt = []\n",
    "\n",
    "#looping across each sample for each trial\n",
    "for sample in all_samples:\n",
    "    X_train_dt = sample.iloc[:, :-1]\n",
    "    y_train_dt = sample.iloc[:, -1]\n",
    "    X_training_sets_dt.append(X_train_dt)\n",
    "    y_training_sets_dt.append(y_train_dt)\n",
    "    \n",
    "    #Separating rows for the test set that were not in the sample\n",
    "    ix_dt = [i for i in scaled_eeg_data.index if i not in sample.index]\n",
    "    test_set_dt = scaled_eeg_data.loc[ix_dt]\n",
    "    X_test_dt = test_set_dt.iloc[:, :-1]\n",
    "    y_test_dt = test_set_dt.iloc[:, -1]\n",
    "    X_testing_sets_dt.append(X_test_dt)\n",
    "    y_testing_sets_dt.append(y_test_dt)\n",
    "    \n",
    "    #Initiating classifier\n",
    "    dt = DecisionTreeClassifier()\n",
    "    \n",
    "    grid_values = [{'criterion': ['gini', 'entropy'], 'max_depth':list(range(1,100,3)), 'min_samples_leaf': list(range(10,100,10))}]\n",
    "    \n",
    "    clf_dt = GridSearchCV(estimator = dt, param_grid = grid_values, cv = StratifiedKFold(n_splits=5),\n",
    "                      scoring = ['accuracy', 'roc_auc_ovr', 'f1_micro'], refit=False, verbose=0)\n",
    "    \n",
    "    model_dt = clf_dt.fit(X_train_dt, y_train_dt)\n",
    "    \n",
    "    accuracy_best_params_dt.append(model_dt.cv_results_['params'][np.argmin(model_dt.cv_results_['rank_test_accuracy'])])\n",
    "    roc_auc_best_params_dt.append(model_dt.cv_results_['params'][np.argmin(model_dt.cv_results_['rank_test_roc_auc_ovr'])])\n",
    "    f1_best_params_dt.append(model_dt.cv_results_['params'][np.argmin(model_dt.cv_results_['rank_test_f1_micro'])])\n",
    "    \n",
    "    all_models_dt.append(model_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy', 'max_depth': 13, 'min_samples_leaf': 10},\n",
       " {'criterion': 'entropy', 'max_depth': 91, 'min_samples_leaf': 10},\n",
       " {'criterion': 'entropy', 'max_depth': 16, 'min_samples_leaf': 10},\n",
       " {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 10},\n",
       " {'criterion': 'entropy', 'max_depth': 13, 'min_samples_leaf': 10}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_best_params_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy', 'max_depth': 13, 'min_samples_leaf': 10},\n",
       " {'criterion': 'entropy', 'max_depth': 67, 'min_samples_leaf': 20},\n",
       " {'criterion': 'entropy', 'max_depth': 13, 'min_samples_leaf': 10},\n",
       " {'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 20},\n",
       " {'criterion': 'entropy', 'max_depth': 79, 'min_samples_leaf': 10}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_best_params_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'criterion': 'entropy', 'max_depth': 13, 'min_samples_leaf': 10},\n",
       " {'criterion': 'entropy', 'max_depth': 91, 'min_samples_leaf': 10},\n",
       " {'criterion': 'entropy', 'max_depth': 16, 'min_samples_leaf': 10},\n",
       " {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 10},\n",
       " {'criterion': 'entropy', 'max_depth': 13, 'min_samples_leaf': 10}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_best_params_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to loop across all models from each metric, train on entire sample, and then predict on test set\n",
    "accuracy_test_errors_dt = []\n",
    "accuracy_train_errors_dt = []\n",
    "for param in accuracy_best_params_dt:\n",
    "    \n",
    "    n_dt = 0\n",
    "    \n",
    "    dt_clf = DecisionTreeClassifier(criterion = param['criterion'], max_depth = param['max_depth'],\n",
    "                                   min_samples_leaf = param['min_samples_leaf'])\n",
    "    model = dt_clf.fit(X_training_sets_dt[n_dt], y_training_sets_dt[n_dt])\n",
    "    \n",
    "    y_pred_dt = model.predict(X_testing_sets_dt[n_dt])\n",
    "    accuracy_test_errors_dt.append(accuracy_score(y_testing_sets_dt[n_dt], y_pred_dt))\n",
    "    \n",
    "    y_pred_train_dt = model.predict(X_training_sets_dt[n_dt])\n",
    "    accuracy_train_errors_dt.append(accuracy_score(y_training_sets_dt[n_dt], y_pred_train_dt))\n",
    "    \n",
    "    n_dt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7828657314629258,\n",
       " 0.7907815631262525,\n",
       " 0.7862725450901804,\n",
       " 0.7805611222444889,\n",
       " 0.7826653306613226]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test_errors_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8804, 0.8938, 0.8912, 0.8652, 0.8804]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train_errors_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_test_errors_dt = []\n",
    "roc_auc_train_errors_dt = []\n",
    "for param in roc_auc_best_params_dt:\n",
    "    \n",
    "    n_dt = 0\n",
    "    \n",
    "    dt_clf2 = DecisionTreeClassifier(criterion = param['criterion'], max_depth = param['max_depth'],\n",
    "                                   min_samples_leaf = param['min_samples_leaf'])\n",
    "    model = dt_clf2.fit(X_training_sets_dt[n_dt], y_training_sets_dt[n_dt])\n",
    "    \n",
    "    y_pred_dt2 = model.predict(X_testing_sets_dt[n_dt])\n",
    "    roc_auc_test_errors_dt.append(roc_auc_score(y_testing_sets_dt[n_dt], y_pred_dt2))\n",
    "    \n",
    "    y_pred_train_dt2 = model.predict(X_training_sets_dt[n_dt])\n",
    "    roc_auc_train_errors_dt.append(roc_auc_score(y_training_sets_dt[n_dt], y_pred_train_dt2))\n",
    "    \n",
    "    n_dt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7758624922187968,\n",
       " 0.7688116125384306,\n",
       " 0.7779214526451702,\n",
       " 0.7713067592948901,\n",
       " 0.7868790014568267]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_test_errors_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.87460040053088,\n",
       " 0.8445774386313115,\n",
       " 0.8783258022109034,\n",
       " 0.8458987518448791,\n",
       " 0.8931138655068463]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_train_errors_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_test_errors_dt = []\n",
    "f1_score_train_errors_dt = []\n",
    "for param in f1_best_params_dt:\n",
    "    \n",
    "    n_dt = 0\n",
    "    \n",
    "    dt_clf3 = DecisionTreeClassifier(criterion = param['criterion'], max_depth = param['max_depth'],\n",
    "                                   min_samples_leaf = param['min_samples_leaf'])\n",
    "    model = dt_clf3.fit(X_training_sets_dt[n_dt], y_training_sets_dt[n_dt])\n",
    "    \n",
    "    y_pred_dt3 = model.predict(X_testing_sets_dt[n_dt])\n",
    "    f1_score_test_errors_dt.append(f1_score(y_testing_sets_dt[n_dt], y_pred_dt3))\n",
    "    \n",
    "    y_pred_train_dt3 = model.predict(X_training_sets_dt[n_dt])\n",
    "    f1_score_train_errors_dt.append(f1_score(y_training_sets_dt[n_dt], y_pred_train_dt3))\n",
    "    \n",
    "    n_dt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7528334287349743,\n",
       " 0.7595454545454545,\n",
       " 0.7554790590935169,\n",
       " 0.7469740634005763,\n",
       " 0.7494538346556283]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_test_errors_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.867244829886591,\n",
       " 0.883956043956044,\n",
       " 0.8792912513842746,\n",
       " 0.8495535714285715,\n",
       " 0.8668744434550312]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_train_errors_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
